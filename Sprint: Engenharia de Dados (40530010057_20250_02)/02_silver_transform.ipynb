{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b7da38c-db75-4546-9f03-4e11f299088b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# MAGIC %md\n",
    "# MAGIC # Silver v5 — Limpeza, Padronização e Modelagem (Long/Wide)\n",
    "# MAGIC\n",
    "# MAGIC ## Objetivo\n",
    "# MAGIC Transformar a camada **Bronze** em dados consistentes e padronizados para análise, gerando:\n",
    "# MAGIC - **silver_prices_long**: formato “longo” (1 linha por `timestamp` + `symbol`)\n",
    "# MAGIC - **silver_prices_wide**: formato “largo” (1 linha por `trade_date`, colunas de close por ativo)\n",
    "# MAGIC\n",
    "# MAGIC ## Entradas\n",
    "# MAGIC - `mvp_finance.bronze_prices_raw`\n",
    "# MAGIC\n",
    "# MAGIC ## Saídas\n",
    "# MAGIC - `mvp_finance.silver_prices_long`\n",
    "# MAGIC - `mvp_finance.silver_prices_wide`\n",
    "# MAGIC\n",
    "# MAGIC ## Regras principais\n",
    "# MAGIC - Tipagem: OHLCV em `double`, datas em `date`, timestamps em `timestamp`\n",
    "# MAGIC - Deduplicação: (`timestamp`, `symbol`) mantendo o último por `ingestion_ts`\n",
    "# MAGIC - WIDE: pivot por `trade_date` com closes por símbolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab533520-70ad-4ce5-ab2e-ecad57a7b86a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 1) Imports e contexto do database\n",
    "# MAGIC Carregamos funções do Spark SQL para cast, datas, deduplicação (Window) e arredondamentos.\n",
    "# COMMAND ----------\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, to_date, to_timestamp, round\n",
    "from pyspark.sql import Window\n",
    "\n",
    "spark.sql(\"USE mvp_finance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aca1f65a-8231-4e0d-8252-8d2d4caaf7ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 2) Leitura da Bronze\n",
    "# MAGIC Lemos a tabela Bronze e validamos rapidamente schema e amostra.\n",
    "# COMMAND ----------\n",
    "bronze_df = spark.table(\"bronze_prices_raw\")\n",
    "\n",
    "print(\"Schema Bronze v5:\")\n",
    "bronze_df.printSchema()\n",
    "display(bronze_df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96946d15-d75b-41d1-ab13-39e2d41be4b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 3) Construção do Silver LONG (padronização e casts)\n",
    "# MAGIC Nesta etapa:\n",
    "# MAGIC - Criamos `date` (DATE) e `timestamp` (TIMESTAMP) a partir de `date_raw`\n",
    "# MAGIC - Fazemos casts de OHLCV para `double`\n",
    "# MAGIC - Arredondamos preços (2 casas) e volume (0 casas)\n",
    "# MAGIC - Removemos registros inválidos (NULL em `timestamp` ou `close`)\n",
    "# COMMAND ----------\n",
    "silver_long = (\n",
    "    bronze_df\n",
    "    .withColumn(\"date\", to_date(col(\"date_raw\")))\n",
    "    .withColumn(\"timestamp\", to_timestamp(col(\"date_raw\")))\n",
    "    .select(\n",
    "        \"timestamp\",\n",
    "        \"date\",\n",
    "        col(\"open\").cast(\"double\").alias(\"open\"),\n",
    "        col(\"high\").cast(\"double\").alias(\"high\"),\n",
    "        col(\"low\").cast(\"double\").alias(\"low\"),\n",
    "        col(\"close\").cast(\"double\").alias(\"close\"),\n",
    "        col(\"volume\").cast(\"double\").alias(\"volume\"),\n",
    "        \"symbol\",\n",
    "        \"source\",\n",
    "        \"ingestion_ts\"\n",
    "    )\n",
    "    .dropna(subset=[\"timestamp\", \"close\", \"symbol\"])\n",
    "    .withColumn(\"open\",   round(col(\"open\"),   2))\n",
    "    .withColumn(\"high\",   round(col(\"high\"),   2))\n",
    "    .withColumn(\"low\",    round(col(\"low\"),    2))\n",
    "    .withColumn(\"close\",  round(col(\"close\"),  2))\n",
    "    .withColumn(\"volume\", round(col(\"volume\"), 0))\n",
    ")\n",
    "\n",
    "print(\"Schema Silver (long) antes do dedup:\")\n",
    "silver_long.printSchema()\n",
    "display(silver_long.limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a6cb125-a148-45a4-96aa-346dc6a276d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 4) Deduplicação do Silver LONG\n",
    "# MAGIC Removemos duplicatas por (`timestamp`, `symbol`) mantendo o registro mais recente\n",
    "# MAGIC com base em `ingestion_ts` (última ingestão vence).\n",
    "# COMMAND ----------\n",
    "w = Window.partitionBy(\"timestamp\", \"symbol\").orderBy(F.col(\"ingestion_ts\").desc())\n",
    "\n",
    "silver_prices_long = (\n",
    "    silver_long\n",
    "    .withColumn(\"row_num\", F.row_number().over(w))\n",
    "    .filter(F.col(\"row_num\") == 1)\n",
    "    .drop(\"row_num\")\n",
    ")\n",
    "\n",
    "display(silver_prices_long.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5edc080-221b-4752-a0f5-649f03acdf27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 5) Quality Gate — Silver LONG (mínimo)\n",
    "# MAGIC Validamos:\n",
    "# MAGIC - Schema obrigatório\n",
    "# MAGIC - Nulls críticos (`timestamp`, `date`, `close`, `symbol`)\n",
    "# MAGIC - Consistência básica (`high >= low`, preços não-negativos quando aplicável)\n",
    "# MAGIC - Duplicidade por (`timestamp`, `symbol`) deve ser zero após dedup\n",
    "# COMMAND ----------\n",
    "required_long_cols = [\n",
    "    \"timestamp\", \"date\", \"open\", \"high\", \"low\", \"close\", \"volume\",\n",
    "    \"symbol\", \"source\", \"ingestion_ts\"\n",
    "]\n",
    "missing_long = [c for c in required_long_cols if c not in silver_prices_long.columns]\n",
    "if missing_long:\n",
    "    raise RuntimeError(f\"[SILVER LONG - QUALITY GATE] Colunas ausentes: {missing_long}\")\n",
    "\n",
    "# Nulls críticos\n",
    "crit = silver_prices_long.select(\n",
    "    F.sum(F.col(\"timestamp\").isNull().cast(\"int\")).alias(\"null_timestamp\"),\n",
    "    F.sum(F.col(\"date\").isNull().cast(\"int\")).alias(\"null_date\"),\n",
    "    F.sum(F.col(\"close\").isNull().cast(\"int\")).alias(\"null_close\"),\n",
    "    F.sum(F.col(\"symbol\").isNull().cast(\"int\")).alias(\"null_symbol\"),\n",
    ").collect()[0]\n",
    "\n",
    "if any([crit[\"null_timestamp\"] > 0, crit[\"null_date\"] > 0, crit[\"null_close\"] > 0, crit[\"null_symbol\"] > 0]):\n",
    "    raise RuntimeError(\n",
    "        \"[SILVER LONG - QUALITY GATE] Nulls críticos: \"\n",
    "        f\"timestamp={crit['null_timestamp']}, date={crit['null_date']}, \"\n",
    "        f\"close={crit['null_close']}, symbol={crit['null_symbol']}\"\n",
    "    )\n",
    "\n",
    "# Consistência OHLC\n",
    "bad_hilo = silver_prices_long.filter(F.col(\"high\") < F.col(\"low\")).count()\n",
    "if bad_hilo > 0:\n",
    "    raise RuntimeError(f\"[SILVER LONG - QUALITY GATE] high < low (qtde={bad_hilo})\")\n",
    "\n",
    "bad_negative = silver_prices_long.filter(\n",
    "    (F.col(\"open\") < 0) | (F.col(\"high\") < 0) | (F.col(\"low\") < 0) | (F.col(\"close\") < 0)\n",
    ").count()\n",
    "if bad_negative > 0:\n",
    "    raise RuntimeError(f\"[SILVER LONG - QUALITY GATE] preços negativos (qtde={bad_negative})\")\n",
    "\n",
    "# Duplicidade (não deve existir após dedup)\n",
    "dups = (\n",
    "    silver_prices_long\n",
    "    .groupBy(\"timestamp\", \"symbol\")\n",
    "    .count()\n",
    "    .filter(F.col(\"count\") > 1)\n",
    "    .count()\n",
    ")\n",
    "if dups > 0:\n",
    "    raise RuntimeError(f\"[SILVER LONG - QUALITY GATE] duplicidade detectada pós-dedup (qtde={dups})\")\n",
    "\n",
    "print(\"[SILVER LONG - QUALITY GATE] OK — validações mínimas passaram.\")\n",
    "display(silver_prices_long.groupBy(\"symbol\").count().orderBy(\"symbol\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d93a5ed1-22f9-47b9-a6dd-e7da21f26644",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# MAGIC %md\n",
    "# MAGIC # Silver v6 — Upgrade Mestre (Long/Wide/Aligned/Returns)\n",
    "# MAGIC\n",
    "# MAGIC ## Objetivo\n",
    "# MAGIC Evoluir a camada Silver para suportar análise quantitativa consistente:\n",
    "# MAGIC - padronização e deduplicação (LONG)\n",
    "# MAGIC - pivot por data (WIDE)\n",
    "# MAGIC - alinhamento de sessão e preenchimento de lacunas (WIDE_ALIGNED)\n",
    "# MAGIC - cálculo de retornos (RETURNS)\n",
    "# MAGIC\n",
    "# MAGIC ## Entradas\n",
    "# MAGIC - `mvp_finance.bronze_prices_raw`\n",
    "# MAGIC\n",
    "# MAGIC ## Saídas\n",
    "# MAGIC - `mvp_finance.silver_prices_long`\n",
    "# MAGIC - `mvp_finance.silver_prices_wide`\n",
    "# MAGIC - `mvp_finance.silver_prices_wide_aligned`\n",
    "# MAGIC - `mvp_finance.silver_returns_wide`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b5c34c6-0859-4726-b954-39d890a7699b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 1) Imports e contexto do database\n",
    "# COMMAND ----------\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, to_date, to_timestamp, round\n",
    "from pyspark.sql import Window\n",
    "\n",
    "spark.sql(\"USE mvp_finance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "869c6ef2-a04c-4c27-ad83-32993e34c568",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 2) Leitura da Bronze e inspeção rápida\n",
    "# COMMAND ----------\n",
    "bronze_df = spark.table(\"bronze_prices_raw\")\n",
    "\n",
    "print(\"Schema Bronze v5:\")\n",
    "bronze_df.printSchema()\n",
    "display(bronze_df.limit(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef970fcc-747f-4b06-a482-16ef3b8e9021",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 3) Silver LONG — padronização, casts e limpeza mínima\n",
    "# MAGIC - `date_raw` → `date` (DATE) e `timestamp` (TIMESTAMP)\n",
    "# MAGIC - OHLCV em `double`\n",
    "# MAGIC - remove linhas inválidas em campos críticos\n",
    "# COMMAND ----------\n",
    "silver_long = (\n",
    "    bronze_df\n",
    "    .withColumn(\"date\", to_date(col(\"date_raw\")))\n",
    "    .withColumn(\"timestamp\", to_timestamp(col(\"date_raw\")))\n",
    "    .select(\n",
    "        \"timestamp\",\n",
    "        \"date\",\n",
    "        col(\"open\").cast(\"double\").alias(\"open\"),\n",
    "        col(\"high\").cast(\"double\").alias(\"high\"),\n",
    "        col(\"low\").cast(\"double\").alias(\"low\"),\n",
    "        col(\"close\").cast(\"double\").alias(\"close\"),\n",
    "        col(\"volume\").cast(\"double\").alias(\"volume\"),\n",
    "        \"symbol\",\n",
    "        \"source\",\n",
    "        \"ingestion_ts\"\n",
    "    )\n",
    "    .dropna(subset=[\"timestamp\", \"date\", \"close\", \"symbol\"])\n",
    "    .withColumn(\"open\",   round(col(\"open\"),   2))\n",
    "    .withColumn(\"high\",   round(col(\"high\"),   2))\n",
    "    .withColumn(\"low\",    round(col(\"low\"),    2))\n",
    "    .withColumn(\"close\",  round(col(\"close\"),  2))\n",
    "    .withColumn(\"volume\", round(col(\"volume\"), 0))\n",
    ")\n",
    "\n",
    "print(\"Schema Silver (long) antes do dedup:\")\n",
    "silver_long.printSchema()\n",
    "display(silver_long.limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaf7c849-7a7f-40fb-bc8b-1d2f166eb946",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 4) Deduplicação (LONG) — (timestamp, symbol)\n",
    "# MAGIC Mantém o registro mais recente por `ingestion_ts`.\n",
    "# COMMAND ----------\n",
    "w = Window.partitionBy(\"timestamp\", \"symbol\").orderBy(F.col(\"ingestion_ts\").desc())\n",
    "\n",
    "silver_prices_long = (\n",
    "    silver_long\n",
    "    .withColumn(\"row_num\", F.row_number().over(w))\n",
    "    .filter(F.col(\"row_num\") == 1)\n",
    "    .drop(\"row_num\")\n",
    ")\n",
    "\n",
    "display(silver_prices_long.limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19d56e54-bb9e-4ccd-9c32-ba59c94e9e36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 5) Quality Gate — Silver LONG\n",
    "# MAGIC Validações mínimas para garantir integridade da série:\n",
    "# MAGIC - schema obrigatório\n",
    "# MAGIC - nulls críticos\n",
    "# MAGIC - consistência OHLC (high >= low)\n",
    "# MAGIC - duplicidade pós-dedup deve ser zero\n",
    "# COMMAND ----------\n",
    "required_long_cols = [\n",
    "    \"timestamp\",\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\",\"symbol\",\"source\",\"ingestion_ts\"\n",
    "]\n",
    "missing_long = [c for c in required_long_cols if c not in silver_prices_long.columns]\n",
    "if missing_long:\n",
    "    raise RuntimeError(f\"[SILVER LONG] Colunas ausentes: {missing_long}\")\n",
    "\n",
    "crit = silver_prices_long.select(\n",
    "    F.sum(F.col(\"timestamp\").isNull().cast(\"int\")).alias(\"null_timestamp\"),\n",
    "    F.sum(F.col(\"date\").isNull().cast(\"int\")).alias(\"null_date\"),\n",
    "    F.sum(F.col(\"close\").isNull().cast(\"int\")).alias(\"null_close\"),\n",
    "    F.sum(F.col(\"symbol\").isNull().cast(\"int\")).alias(\"null_symbol\"),\n",
    ").collect()[0]\n",
    "\n",
    "if crit[\"null_timestamp\"] or crit[\"null_date\"] or crit[\"null_close\"] or crit[\"null_symbol\"]:\n",
    "    raise RuntimeError(\n",
    "        \"[SILVER LONG] Nulls críticos: \"\n",
    "        f\"timestamp={crit['null_timestamp']} date={crit['null_date']} \"\n",
    "        f\"close={crit['null_close']} symbol={crit['null_symbol']}\"\n",
    "    )\n",
    "\n",
    "bad_hilo = silver_prices_long.filter(F.col(\"high\") < F.col(\"low\")).count()\n",
    "if bad_hilo > 0:\n",
    "    raise RuntimeError(f\"[SILVER LONG] high < low (qtde={bad_hilo})\")\n",
    "\n",
    "dups = (\n",
    "    silver_prices_long.groupBy(\"timestamp\",\"symbol\").count().filter(F.col(\"count\") > 1).count()\n",
    ")\n",
    "if dups > 0:\n",
    "    raise RuntimeError(f\"[SILVER LONG] duplicidade pós-dedup (qtde={dups})\")\n",
    "\n",
    "print(\"[SILVER LONG] OK\")\n",
    "display(silver_prices_long.groupBy(\"symbol\").count().orderBy(\"symbol\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa3a7ba0-4fa5-4b82-9086-2a1e295b917b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 6) Persistência — Silver LONG\n",
    "# COMMAND ----------\n",
    "silver_prices_long.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver_prices_long\")\n",
    "print(\"✅ silver_prices_long criada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bd55b53-4eea-4a5c-b18e-567da29227cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 7) Silver WIDE — pivot por data (trade_date)\n",
    "# MAGIC - 1 linha por dia\n",
    "# MAGIC - colunas com `close` por símbolo\n",
    "# MAGIC - renomeia para padrão analítico\n",
    "# COMMAND ----------\n",
    "wide_raw = (\n",
    "    silver_prices_long\n",
    "    .groupBy(\"date\")\n",
    "    .pivot(\"symbol\")\n",
    "    .agg(F.first(\"close\"))\n",
    ")\n",
    "\n",
    "# renomeia as colunas (dinâmico, mas padronizado)\n",
    "rename_map = {}\n",
    "for c in wide_raw.columns:\n",
    "    if c == \"date\":\n",
    "        continue\n",
    "    cu = str(c).upper()\n",
    "    if cu.startswith(\"IBOV\"):\n",
    "        rename_map[c] = \"ibov_close\"\n",
    "    elif cu.startswith(\"SP500\"):\n",
    "        rename_map[c] = \"sp500_close\"\n",
    "    elif cu.startswith(\"DXY\"):\n",
    "        rename_map[c] = \"dxy_close\"\n",
    "\n",
    "silver_prices_wide = wide_raw\n",
    "for old, new in rename_map.items():\n",
    "    silver_prices_wide = silver_prices_wide.withColumnRenamed(old, new)\n",
    "\n",
    "silver_prices_wide = silver_prices_wide.withColumnRenamed(\"date\", \"trade_date\")\n",
    "\n",
    "print(\"Schema Silver wide:\")\n",
    "silver_prices_wide.printSchema()\n",
    "display(silver_prices_wide.orderBy(\"trade_date\").limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3f910e0-eab8-468d-85b8-d5a6bc1c868b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 8) Quality Gate — Silver WIDE (chave diária)\n",
    "# MAGIC - `trade_date` não nulo\n",
    "# MAGIC - 1 linha por dia (sem duplicidade)\n",
    "# COMMAND ----------\n",
    "if \"trade_date\" not in silver_prices_wide.columns:\n",
    "    raise RuntimeError(\"[SILVER WIDE] trade_date ausente\")\n",
    "\n",
    "null_td = silver_prices_wide.filter(F.col(\"trade_date\").isNull()).count()\n",
    "if null_td > 0:\n",
    "    raise RuntimeError(f\"[SILVER WIDE] trade_date NULL (qtde={null_td})\")\n",
    "\n",
    "dups_td = silver_prices_wide.groupBy(\"trade_date\").count().filter(F.col(\"count\") > 1).count()\n",
    "if dups_td > 0:\n",
    "    raise RuntimeError(f\"[SILVER WIDE] duplicidade por trade_date (qtde={dups_td})\")\n",
    "\n",
    "print(\"[SILVER WIDE] OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "232a8725-d960-4f06-9d0d-95003c37c183",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 9) Persistência — Silver WIDE\n",
    "# COMMAND ----------\n",
    "spark.sql(\"DROP TABLE IF EXISTS silver_prices_wide\")\n",
    "silver_prices_wide.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver_prices_wide\")\n",
    "print(\"✅ silver_prices_wide criada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb8d401d-d783-4f2b-92be-3619caa82a27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 10) Silver WIDE_ALIGNED — calendário + preenchimento de lacunas\n",
    "# MAGIC Esta é a melhoria principal para análise:\n",
    "# MAGIC - Criamos um calendário diário contínuo entre min e max\n",
    "# MAGIC - Fazemos `left join` para inserir dias faltantes\n",
    "# MAGIC - Aplicamos **forward-fill** nos closes (último valor conhecido)\n",
    "# MAGIC\n",
    "# MAGIC **Por que isso é importante?**\n",
    "# MAGIC - Correlação/retornos exigem séries alinhadas\n",
    "# MAGIC - Mercados têm feriados diferentes; sem alinhamento, a matriz fica quebrada\n",
    "# COMMAND ----------\n",
    "minmax = silver_prices_wide.select(\n",
    "    F.min(\"trade_date\").alias(\"min_date\"),\n",
    "    F.max(\"trade_date\").alias(\"max_date\")\n",
    ").collect()[0]\n",
    "\n",
    "min_date = minmax[\"min_date\"]\n",
    "max_date = minmax[\"max_date\"]\n",
    "\n",
    "calendar_df = (\n",
    "    spark.sql(f\"SELECT explode(sequence(to_date('{min_date}'), to_date('{max_date}'), interval 1 day)) AS trade_date\")\n",
    ")\n",
    "\n",
    "wide_cal = (\n",
    "    calendar_df\n",
    "    .join(silver_prices_wide, on=\"trade_date\", how=\"left\")\n",
    "    .orderBy(\"trade_date\")\n",
    ")\n",
    "\n",
    "# forward-fill por coluna (window acumulada)\n",
    "w_ffill = Window.orderBy(\"trade_date\").rowsBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "for c in [\"ibov_close\", \"sp500_close\", \"dxy_close\"]:\n",
    "    if c in wide_cal.columns:\n",
    "        wide_cal = wide_cal.withColumn(\n",
    "            c,\n",
    "            F.last(F.col(c), ignorenulls=True).over(w_ffill)\n",
    "        )\n",
    "\n",
    "silver_prices_wide_aligned = wide_cal\n",
    "\n",
    "display(silver_prices_wide_aligned.limit(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cf94a14-54a3-4f08-acdd-748cc47067ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 11) Alinhamento de sessão (opcional, mas “nível mestre”)\n",
    "# MAGIC Como os ativos globais fecham em horários diferentes do mercado BR,\n",
    "# MAGIC uma abordagem comum é usar **SP500/DXY do dia anterior** como “informação disponível”\n",
    "# MAGIC para o pregão brasileiro do dia atual.\n",
    "# MAGIC\n",
    "# MAGIC Criamos colunas *_prev (shift de 1 dia) para globais.\n",
    "# COMMAND ----------\n",
    "# COMMAND ----------\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "w_shift = Window.orderBy(\"trade_date\")\n",
    "\n",
    "# Detecta colunas de preço (tudo que não é trade_date e não é coluna derivada)\n",
    "base_cols = [c for c in silver_prices_wide_aligned.columns if c != \"trade_date\"]\n",
    "\n",
    "# Cria *_prev para todas\n",
    "df = silver_prices_wide_aligned\n",
    "for c in base_cols:\n",
    "    # evita recriar se já existir\n",
    "    prev_col = f\"{c}_prev\"\n",
    "    if prev_col not in df.columns:\n",
    "        df = df.withColumn(prev_col, F.lag(F.col(c), 1).over(w_shift))\n",
    "\n",
    "silver_prices_wide_aligned = df\n",
    "\n",
    "# Exibe um recorte (escolhe algumas colunas automaticamente)\n",
    "sample_cols = [\"trade_date\"] + base_cols[:6] + [f\"{c}_prev\" for c in base_cols[:6]]\n",
    "display(silver_prices_wide_aligned.select(*sample_cols).limit(15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02d75471-9ad9-4c69-a5a6-1992dd956639",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 12) Quality Gate — WIDE_ALIGNED (genérico)\n",
    "# MAGIC - `trade_date` sem NULL\n",
    "# MAGIC - Reporta NULLs por coluna (após forward-fill)\n",
    "# MAGIC - Permite NULLs no início (até o 1º valor existir) e informa quantos são\n",
    "# MAGIC\n",
    "# MAGIC Observação:\n",
    "# MAGIC - Aqui assumimos que as colunas dos ativos são todas as colunas exceto `trade_date`\n",
    "# MAGIC - Colunas derivadas como `*_prev` podem ser excluídas do gate (opcional)\n",
    "# COMMAND ----------\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# 1) trade_date obrigatório e não-nulo\n",
    "if \"trade_date\" not in silver_prices_wide_aligned.columns:\n",
    "    raise RuntimeError(\"[SILVER WIDE_ALIGNED] Coluna trade_date não existe.\")\n",
    "\n",
    "null_trade_date = silver_prices_wide_aligned.filter(F.col(\"trade_date\").isNull()).count()\n",
    "if null_trade_date > 0:\n",
    "    raise RuntimeError(f\"[SILVER WIDE_ALIGNED] trade_date NULL (qtde={null_trade_date})\")\n",
    "\n",
    "# 2) Define quais colunas entram no gate\n",
    "#    - por padrão: todas exceto trade_date\n",
    "#    - opcional: excluir colunas derivadas *_prev (geralmente são esperadas ter NULL no início)\n",
    "asset_cols = [\n",
    "    c for c in silver_prices_wide_aligned.columns\n",
    "    if c != \"trade_date\" and not c.endswith(\"_prev\")\n",
    "]\n",
    "\n",
    "if not asset_cols:\n",
    "    raise RuntimeError(\"[SILVER WIDE_ALIGNED] Nenhuma coluna de ativo encontrada para validação.\")\n",
    "\n",
    "# 3) Calcula NULLs por coluna (sum(isNull))\n",
    "null_exprs = [\n",
    "    F.sum(F.col(c).isNull().cast(\"int\")).alias(f\"null_{c}\")\n",
    "    for c in asset_cols\n",
    "]\n",
    "\n",
    "nulls_row = silver_prices_wide_aligned.select(*null_exprs).collect()[0].asDict()\n",
    "\n",
    "# 4) Imprime um resumo enxuto (ordenado do pior para o melhor)\n",
    "nulls_sorted = sorted(nulls_row.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "print(\"[SILVER WIDE_ALIGNED] Nulls após ffill (top 20 colunas):\")\n",
    "for k, v in nulls_sorted[:20]:\n",
    "    print(f\"  - {k}: {v}\")\n",
    "\n",
    "# 5) (Opcional) Gate mais rígido:\n",
    "#    exigir que, após o 1º ponto válido, a série não tenha mais NULLs.\n",
    "#    Aqui deixamos apenas como diagnóstico para não quebrar casos com ativos muito curtos.\n",
    "#\n",
    "#    Se você quiser ativar o modo rígido depois, eu te passo a versão que calcula\n",
    "#    o \"primeiro trade_date válido\" por coluna e valida NULLs a partir dali.\n",
    "print(\"[SILVER WIDE_ALIGNED] OK (modo informativo).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1edfda8-1623-473b-a41a-112b15c48188",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 13) Silver RETURNS — retornos diários (%) (genérico)\n",
    "# MAGIC Calculamos retornos percentuais para uso na Gold e validação de hipóteses.\n",
    "# MAGIC\n",
    "# MAGIC **Definição**\n",
    "# MAGIC - `X_prev = lag(X, 1)`\n",
    "# MAGIC - `X_ret  = (X / X_prev) - 1`\n",
    "# MAGIC\n",
    "# MAGIC **Por que retornos**\n",
    "# MAGIC - Retornos são mais adequados para correlação e modelagem, pois preços não são estacionários.\n",
    "# COMMAND ----------\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Janela temporal (garante ordenação por trade_date)\n",
    "w_shift = Window.orderBy(\"trade_date\")\n",
    "\n",
    "df = silver_prices_wide_aligned\n",
    "\n",
    "# Colunas base (ativos): tudo exceto trade_date e colunas já derivadas\n",
    "asset_cols = [\n",
    "    c for c in df.columns\n",
    "    if c != \"trade_date\" and not c.endswith(\"_prev\") and not c.endswith(\"_ret\")\n",
    "]\n",
    "\n",
    "if not asset_cols:\n",
    "    raise RuntimeError(\"[SILVER RETURNS] Nenhuma coluna de ativo encontrada.\")\n",
    "\n",
    "# 1) cria *_prev (lag 1)\n",
    "for c in asset_cols:\n",
    "    prev_col = f\"{c}_prev\"\n",
    "    if prev_col not in df.columns:\n",
    "        df = df.withColumn(prev_col, F.lag(F.col(c), 1).over(w_shift))\n",
    "\n",
    "# 2) cria *_ret\n",
    "for c in asset_cols:\n",
    "    prev_col = f\"{c}_prev\"\n",
    "    ret_col  = f\"{c}_ret\"\n",
    "    if ret_col not in df.columns:\n",
    "        df = df.withColumn(ret_col, (F.col(c) / F.col(prev_col)) - F.lit(1))\n",
    "\n",
    "# 3) seleciona colunas finais (organizadas)\n",
    "price_cols = asset_cols\n",
    "prev_cols  = [f\"{c}_prev\" for c in asset_cols]\n",
    "ret_cols   = [f\"{c}_ret\" for c in asset_cols]\n",
    "\n",
    "silver_returns_wide = df.select(\n",
    "    \"trade_date\",\n",
    "    *price_cols,\n",
    "    *prev_cols,\n",
    "    *ret_cols\n",
    ")\n",
    "\n",
    "display(silver_returns_wide.orderBy(\"trade_date\").limit(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "524b3cac-960b-480a-ace9-69df9a6aa10d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ### 13.1) Quality Gate — RETURNS (sanity)\n",
    "# MAGIC - `trade_date` não nulo\n",
    "# MAGIC - Retornos em faixa conservadora (ex.: ±50%) para evitar outliers por dados ruins\n",
    "# COMMAND ----------\n",
    "null_td = silver_returns_wide.filter(F.col(\"trade_date\").isNull()).count()\n",
    "if null_td > 0:\n",
    "    raise RuntimeError(f\"[SILVER RETURNS] trade_date NULL (qtde={null_td})\")\n",
    "\n",
    "abs_limit = 0.50\n",
    "ret_cols = [c for c in silver_returns_wide.columns if c.endswith(\"_ret\")]\n",
    "\n",
    "# evita quebrar se alguns ativos estiverem muito curtos (ret pode ser null no início)\n",
    "bad = (\n",
    "    silver_returns_wide\n",
    "    .dropna(subset=ret_cols)\n",
    "    .filter(F.greatest(*[F.abs(F.col(c)) for c in ret_cols]) > abs_limit)\n",
    "    .count()\n",
    ")\n",
    "\n",
    "if bad > 0:\n",
    "    display(\n",
    "        silver_returns_wide\n",
    "        .dropna(subset=ret_cols)\n",
    "        .filter(F.greatest(*[F.abs(F.col(c)) for c in ret_cols]) > abs_limit)\n",
    "        .select(\"trade_date\", *ret_cols)\n",
    "        .orderBy(\"trade_date\")\n",
    "        .limit(50)\n",
    "    )\n",
    "    raise RuntimeError(f\"[SILVER RETURNS] retornos fora do limite ±{abs_limit*100:.0f}% (qtde={bad})\")\n",
    "\n",
    "print(\"[SILVER RETURNS] OK\")\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS silver_returns_wide\")\n",
    "silver_returns_wide.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver_returns_wide\")\n",
    "print(\"✅ silver_returns_wide criada\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52845597-3a93-4c9e-afde-ce4564864d8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# identifica colunas de retorno\n",
    "ret_cols = [c for c in silver_returns_wide.columns if c.endswith(\"_ret\")]\n",
    "\n",
    "if not ret_cols:\n",
    "    raise RuntimeError(\"[SILVER RETURNS] Nenhuma coluna *_ret encontrada para validação.\")\n",
    "\n",
    "# remove linhas iniciais (onde todos os returns podem estar NULL)\n",
    "# (mantemos apenas linhas que tenham pelo menos 1 retorno não nulo)\n",
    "ret_clean = silver_returns_wide.filter(\n",
    "    F.greatest(*[F.col(c).isNotNull().cast(\"int\") for c in ret_cols]) == 1\n",
    ")\n",
    "\n",
    "# 1) finitude: NaN (Spark tem isnan para double/float)\n",
    "nan_expr = None\n",
    "for c in ret_cols:\n",
    "    e = F.sum(F.isnan(F.col(c)).cast(\"int\")).alias(f\"nan_{c}\")\n",
    "    nan_expr = e if nan_expr is None else nan_expr  # placeholder (vamos fazer select abaixo)\n",
    "\n",
    "nan_counts = (\n",
    "    ret_clean\n",
    "    .select(*[F.sum(F.isnan(F.col(c)).cast(\"int\")).alias(c) for c in ret_cols])\n",
    "    .collect()[0]\n",
    "    .asDict()\n",
    ")\n",
    "\n",
    "total_nan = sum(nan_counts.values())\n",
    "if total_nan > 0:\n",
    "    print(\"[SILVER RETURNS] NaNs detectados (por coluna):\")\n",
    "    for k, v in sorted(nan_counts.items(), key=lambda kv: kv[1], reverse=True):\n",
    "        if v > 0:\n",
    "            print(f\"  - {k}: {v}\")\n",
    "    raise RuntimeError(f\"[SILVER RETURNS] Existem NaNs em retornos (total={total_nan}).\")\n",
    "\n",
    "# 2) finitude: infinitos (aproximação robusta: abs(ret) muito grande)\n",
    "#    Como Infinity pode aparecer em divisão por zero, tratamos com:\n",
    "#    - prev == 0 => ret explode\n",
    "#    - ou ret absurdamente alto\n",
    "#    Nota: retornos percentuais reais não deveriam ter magnitude gigantesca.\n",
    "INF_GUARD = 10.0  # 1000% como guarda para detectar inf/erro grotesco\n",
    "\n",
    "inf_like = ret_clean.filter(\n",
    "    F.greatest(*[F.abs(F.col(c)) for c in ret_cols]) > F.lit(INF_GUARD)\n",
    ")\n",
    "\n",
    "inf_cnt = inf_like.count()\n",
    "if inf_cnt > 0:\n",
    "    display(inf_like.select(\"trade_date\", *ret_cols).orderBy(\"trade_date\"))\n",
    "    raise RuntimeError(f\"[SILVER RETURNS] Retornos com magnitude > {INF_GUARD} (possível Inf/divisão por zero). qtde={inf_cnt}\")\n",
    "\n",
    "# 3) sanity: retornos fora do limite conservador\n",
    "abs_limit = 0.50  # ajuste conforme universo (ex.: cripto pode exigir maior)\n",
    "\n",
    "bad = ret_clean.filter(\n",
    "    F.greatest(*[F.abs(F.col(c)) for c in ret_cols]) > F.lit(abs_limit)\n",
    ")\n",
    "\n",
    "bad_cnt = bad.count()\n",
    "if bad_cnt > 0:\n",
    "    # mostra os maiores outliers (ordena pelo maior retorno absoluto entre colunas)\n",
    "    bad_ranked = bad.withColumn(\n",
    "        \"_max_abs_ret\",\n",
    "        F.greatest(*[F.abs(F.col(c)) for c in ret_cols])\n",
    "    ).orderBy(F.col(\"_max_abs_ret\").desc())\n",
    "\n",
    "    display(bad_ranked.select(\"trade_date\", \"_max_abs_ret\", *ret_cols).limit(200))\n",
    "    raise RuntimeError(f\"[SILVER RETURNS] Retornos fora do limite conservador ±{abs_limit*100:.0f}% (qtde={bad_cnt})\")\n",
    "\n",
    "print(\"[SILVER RETURNS] OK — sanity check passou.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f564249-5f99-4bc3-b157-d317fde79ca8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "# MAGIC %md\n",
    "# MAGIC ## 15) Persistência — WIDE_ALIGNED e RETURNS\n",
    "# COMMAND ----------\n",
    "spark.sql(\"DROP TABLE IF EXISTS silver_prices_wide_aligned\")\n",
    "silver_prices_wide_aligned.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver_prices_wide_aligned\")\n",
    "print(\"✅ silver_prices_wide_aligned criada\")\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS silver_returns_wide\")\n",
    "silver_returns_wide.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver_returns_wide\")\n",
    "print(\"✅ silver_returns_wide criada\")\n",
    "\n",
    "spark.sql(\"SELECT COUNT(*) FROM silver_prices_wide_aligned\").show()\n",
    "spark.sql(\"SELECT COUNT(*) FROM silver_returns_wide\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6571265d-94e0-4285-9747-9232b577b04d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Conclusão — Camada Silver\n",
    "\n",
    "A camada **Silver** consolida os dados provenientes da Bronze em um conjunto **limpo, consistente e estatisticamente utilizável**, estabelecendo a base correta para análises quantitativas e construção da camada Gold.\n",
    "\n",
    "### Principais entregas desta camada\n",
    "  - Padronização completa de tipos e datas (`date`, `timestamp`)\n",
    "  - Remoção de duplicidades por `(timestamp, symbol)` com critério determinístico (`ingestion_ts`)\n",
    "  - Construção do formato **Long** (`silver_prices_long`), adequado para:\n",
    "  - cálculo de indicadores técnicos\n",
    "  - janelas temporais por ativo\n",
    "  - Construção do formato **Wide** (`silver_prices_wide`), com:\n",
    "  - 1 linha por dia (`trade_date`)\n",
    "  - colunas por ativo (closes)\n",
    "  - Alinhamento de calendário entre mercados com:\n",
    "  - calendário contínuo\n",
    "  - forward-fill controlado\n",
    "  - Geração de **retornos diários percentuais**, garantindo séries estacionárias para:\n",
    "  - correlação\n",
    "  - modelagem estatística\n",
    "  - machine learning\n",
    "\n",
    "### Qualidade e rigor analítico\n",
    "Foram aplicados **Quality Gates explícitos**, assegurando que:\n",
    "  - chaves temporais não contenham valores nulos\n",
    "  - não existam duplicidades após deduplicação\n",
    "  - preços respeitem consistência básica (`high ≥ low`)\n",
    "  - retornos extremos sejam detectados como possíveis problemas de dado\n",
    "\n",
    "NULLs remanescentes são **intencionais e esperados** apenas:\n",
    "  - no início das séries (aquecimento de janelas)\n",
    "  - antes da existência do primeiro valor válido após forward-fill\n",
    "\n",
    "### Resultado final\n",
    "Ao final desta etapa, os dados encontram-se:\n",
    "  - alinhados temporalmente entre ativos locais e globais\n",
    "  - com estrutura adequada para correlação estática e dinâmica\n",
    "  - prontos para cálculo de features avançadas na camada Gold\n",
    "\n",
    "Esta camada estabelece a **fronteira clara entre tratamento de dados e análise**, permitindo que a Gold opere com foco exclusivo em **insights, sinais e modelagem**, sem necessidade de correções estruturais adicionais.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_silver_transform",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
